{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1gyGp8NMqwQ"
      },
      "outputs": [],
      "source": [
        "# Facial Recognition System using TensorFlow and OpenCV\n",
        "# ======================================================\n",
        "#\n",
        "# This notebook demonstrates a complete pipeline for facial detection and recognition.\n",
        "# It uses:\n",
        "#   - OpenCV Haar Cascade for face detection.\n",
        "#   - A convolutional neural network (CNN) built with TensorFlow/Keras to recognize faces.\n",
        "#\n",
        "# The CNN is trained from scratch on the LFW (Labeled Faces in the Wild) dataset.\n",
        "# After training, the system allows the user to upload an image,\n",
        "# detect faces within it, and classify each face into one of the known identities.\n",
        "\n",
        "# 1. Import necessary libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# 2. Load the LFW dataset (only consider people with at least 50 images)\n",
        "lfw_people = fetch_lfw_people(min_faces_per_person=50, resize=0.4)\n",
        "X = lfw_people.images  # grayscale images\n",
        "y = lfw_people.target  # numeric labels\n",
        "target_names = lfw_people.target_names  # names corresponding to labels\n",
        "\n",
        "print(\"Dataset shape:\", X.shape)\n",
        "print(\"Number of classes:\", len(target_names))\n",
        "print(\"Classes:\", target_names)\n",
        "\n",
        "# 3. Preprocess the data\n",
        "# Expand dimension to add channel (needed for CNN input)\n",
        "X = np.expand_dims(X, -1)\n",
        "# Normalize pixel values to [0,1]\n",
        "X = X.astype('float32') / 255.0\n",
        "\n",
        "# 4. Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Convert labels to categorical (one-hot encoding)\n",
        "num_classes = len(target_names)\n",
        "y_train_cat = to_categorical(y_train, num_classes)\n",
        "y_test_cat = to_categorical(y_test, num_classes)\n",
        "\n",
        "# 5. Build the CNN model for face recognition\n",
        "input_shape = X_train.shape[1:]  # e.g., (50, 37, 1)\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# 6. Train the model\n",
        "# For demonstration purposes, we use a small number of epochs.\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "\n",
        "history = model.fit(X_train, y_train_cat, epochs=epochs, batch_size=batch_size, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model on test set\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test_cat)\n",
        "print(\"Test accuracy: {:.2f}%\".format(test_acc * 100))\n",
        "\n",
        "# 7. Save the trained model (optional)\n",
        "model.save('face_recognition_model.h5')\n",
        "\n",
        "# 8. Download Haar Cascade file for face detection (if not already present)\n",
        "!wget -q https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
        "\n",
        "# 9. Initialize the Haar Cascade classifier\n",
        "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "\n",
        "# 10. Function to detect faces and perform recognition on an input image\n",
        "def detect_and_recognize(image_path):\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(\"Error: Unable to read image!\")\n",
        "        return\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "    print(\"Detected {} face(s)\".format(len(faces)))\n",
        "\n",
        "    # For each detected face, perform recognition\n",
        "    for (x, y, w, h) in faces:\n",
        "        # Extract face ROI and resize to match model's expected input size\n",
        "        face_roi = gray[y:y+h, x:x+w]\n",
        "        face_resized = cv2.resize(face_roi, (input_shape[1], input_shape[0]))\n",
        "        face_resized = face_resized.astype('float32') / 255.0\n",
        "        face_resized = np.expand_dims(face_resized, axis=-1)\n",
        "        face_resized = np.expand_dims(face_resized, axis=0)  # add batch dimension\n",
        "\n",
        "        # Predict identity using the CNN\n",
        "        pred = model.predict(face_resized)\n",
        "        class_idx = np.argmax(pred, axis=1)[0]\n",
        "        label = target_names[class_idx]\n",
        "        confidence = pred[0][class_idx]\n",
        "\n",
        "        # Draw rectangle and label on the original image\n",
        "        cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "        text = \"{}: {:.2f}%\".format(label, confidence * 100)\n",
        "        cv2.putText(image, text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (36,255,12), 2)\n",
        "\n",
        "    # Convert image from BGR to RGB for display\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(image_rgb)\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Face Detection & Recognition\")\n",
        "    plt.show()\n",
        "\n",
        "# 11. Testing the system: upload an image and perform detection and recognition\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Assume the user uploads one image, get its filename.\n",
        "if uploaded:\n",
        "    image_filename = list(uploaded.keys())[0]\n",
        "    detect_and_recognize(image_filename)\n"
      ]
    }
  ]
}